# Supabase Configuration
SUPABASE_URL=https://dpbbsbrflunziohzoawt.supabase.co
SUPABASE_SERVICE_KEY=sb_publishable_jl7GOBysYziSjgDadUWewg_fIT_zA2H

# Ollama Configuration (optional - these are the defaults)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Whisper Configuration (optional - these are the defaults)
# Model options: tiny, base, small, medium, large-v2, large-v3
# Larger models = better accuracy but slower and more memory
WHISPER_MODEL_SIZE=base
# Device: cpu or cuda (use cuda if you have an NVIDIA GPU)
WHISPER_DEVICE=cpu